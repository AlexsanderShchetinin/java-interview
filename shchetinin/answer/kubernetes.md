## Общая информация

**Kubernetes, также известная как K8s**, — это система с открытым исходным кодом (Go) для автоматизации развертывания, 
масштабирования и управления контейнерными приложениями.

«узел» в Kubernetes — это сущность, которая отвечает за выполнение некоторой вычислительной 
работы.

**NODE** может быть физическим сервером. Компьютер. Экземпляр в облаке.

А несколько узлов, работающих вместе для выполнения различных задач, называются **КЛАСТЕРОМ**

в кластере Kubernetes есть один узел, который отвечает за управление всеми остальными узлами. 
Этот конкретный узел называется узлом **"MASTER"**, в то время как все остальные узлы называются узлами **WORKER**. 
Это называется концепцией **«МАСТЕР-СЛЭЙВ»**

в кластерах Kubernetes есть **PODS** для выполнения всех задач и запуска приложений.
В каком-то смысле можно сказать, что как сотрудник — это базовая единица любой организации, 
так и pod-модуль — это базовая единица развертывания в любом кластере Kubernetes.

На самом деле капсула — это просто набор из одного или нескольких контейнеров. А контейнеры внутри пода запускают определенное приложение.

Кроме того, о pod говорят, что он «самодостаточен». 
Это означает, что он создает в себе среду, которая подходит только для запуска одного конкретного 
контейнера приложения, назначенного ему. 
Что-то вроде мини-компьютера, созданного специально для приложения!

### Pod Networking and Services

каждому поду присваивается свой собственный IP-адрес, который может быть использован другими 
подами для связи друг с другом. 
Видите ли, если капсула самодостаточна, то она обязательно должна иметь некоторые сетевые возможности!

если pod умирает, на его место создается новый. Но новый pod означает новый IP-адрес. 
И когда это происходит, другие поды не знают об этом изменении и продолжают пытаться подключиться к старому IP-адресу.

Kubernetes позволяет прикреплять ресурс **«SERVICE»** к поду. 
Сервис, всегда будет иметь фиксированный IP-адрес. 
Всем остальным подам просто нужно знать IP-адрес сервиса, а не IP-адрес пода.

И, скажем, если под, к которому присоединен сервис, умрет, он просто снова прикрепится к новому созданному поду. 
Сервис не умирает вместе с подом, и поэтому IP-адрес остается постоянным.


### Пространства имен

Наступит время, когда кластер будет использоваться несколькими пользователями и командами, 
которые запускают свои собственные приложения (время может наступить и сейчас). 
Но все становится сложнее, когда запущено много приложений, и вы не знаете, какое приложение кому принадлежит.

Подумайте об этом. Один кластер используется тремя командами: 
микрослужбами, базой данных и журналами. 
Теперь, если и у команды сервисов, и у команды базы данных есть приложение с именем "the-duplicate-application-name". 
Как понять, к какой команде он должен принадлежать?

NAMESPACE — это способ, с помощью которого ресурсы кластера могут быть разделены между пользователями или командами. 
Таким образом, в нашем предыдущем примере может быть выделено одно пространство имен для каждой
из служб, базы данных и команды ведения журнала.

Каждая команда будет работать в своем собственном пространстве имен, 
и поскольку пространство имен имеет свою долю ресурсов, оно не будет мешать другим ресурсам.
Теперь, даже если у двух команд есть приложение с одинаковым именем, "the-duplicate-application-name",
это не будет иметь значения, потому что два приложения будут работать изолированно в своем собственном пространстве имен.

### Что такое Pod?

Pod — это группа из одного/нескольких Контейнеров.
Капсула в самолете/космическом корабле является «автономной» и выполняет определенную функцию. 
То же самое относится и к поду Kubernetes. Он самодостаточен и выполняет одну конкретную функцию.

Если вы хотите выполнить работу в кластере Kubernetes, вам нужно создать Pod. 
Хотите запустить веб-сервис? Pod! Хотите, чтобы процесс работал в фоновом режиме? Pod! 
Так что можно сказать, чтобы запустить любое приложение, вам нужен под.

Контейнеры запускают приложения. Так почему же Kubernetes взял на вооружение концепцию «пода»? 
Почему бы не использовать сам контейнер?

Потому что в Pod есть нечто большее, чем просто сказать «группа из одного/нескольких контейнеров». 
И ответ кроется в слове «самодостаточный».

Под — это не просто контейнер, он предоставляет вам все «аксессуары». 
Иногда недостаточно запустить код приложения, верно? 
Вам нужны такие вещи, как сеть, хранилище и конкретная среда, которая подходит для этого.
В pod есть все это.

- У вас есть сетевые возможности, такие как присвоение IP-адреса поду.
- Затем вы получили политику перезапуска. Что делать, если контейнер неожиданно вышел из строя/вылетел/завершил работу. 
- Может быть, перезагрузить контейнер? Это предусмотрено политикой перезапуска.
- И, наконец, у вас есть контейнерные зонды.

### Multi-Container Pods

В большинстве случаев в поде будет работать один контейнер. 
Случай когда в одном поде запущено несколько контейнеров не так широко используется.

Такого рода ситуации называются **«мультиконтейнерными» подами**. 
Обычно, если у вас есть контейнеры, которые тесно связаны друг с другом 
(т.е. они слишком сильно зависят друг от друга), то имеет смысл выбрать под с несколькими контейнерами.

### Life of Pod

+ Pending State(состояние ожидания)
Сначала **планировщик кластера** должен был решить, к какому узлу назначить наш под. 
Это занимает некоторое время. Тем временем под находится в состоянии ожидания
*__Состояние ожидания__ — это когда модуль pod принят кластером, но еще не назначен конкретному узлу для выполнения. 
Сюда также входит время, в течение которого pod извлекает образы контейнеров*

+ Running State(Состояние выполнения)
Ожидание закончилось! Наш pod был назначен узлу и был готов к работе. 
Контейнеры тоже работают вместе с подом.
*__Состояние выполнения__ — 
это когда модуль pod назначен узлу и один из его контейнеров начал работу или (пере)запускается.*

+ Success State(состояние успеха)
*__Состояние Succeeded__ — 
это когда все контейнеры успешно завершаются и их не нужно перезапускать*

+ Failed State(состояние провала)
*__Состояние Failed__ возникает, 
когда контейнеры завершают работу со сбоем или завершаются системой из-за какой-либо ошибки*

+ Unknown State()
*__Неизвестное состояние__, 
когда состояние пода обычно не может быть определено из-за какого-либо сбоя связи*


### Container Probes

+ Liveness Probe(проба работы контейнеров)
проба проверит, является ли контейнер «живым» или нет.
если контейнер запущен и работает (что также будет означать, что pod тоже работает). 
то он живой, и никаких действий не требуется. 
Но если контейнер «мертв» или завершен, 
то Kubernetes предпримет действие на основе политики перезапуска пода.

+ Readiness Probe(проба готовности пода к работе)
Проверка готовности гарантирует, готов ли контейнер к началу приема запросов.
Например, если в вашем поде есть контейнеры, на которых работает веб-служба, 
то будет полезно проверить готовность, чтобы узнать, 
когда контейнер может начать принимать запросы на ввод. 
Если проверка готовности завершается успешно, Kubernetes начинает направлять трафик на модуль pod и его контейнер

+ Startup Probe(проба готовности пода к старту)
Проба проверит, запустился ли контейнер или нет. 
Это можно использовать в тех случаях, когда контейнеру требуется время для запуска и подготовки. 
Особенно, если задач, которые происходят при запуске контейнера, очень много.


## Архитектура Kubernetes

#### Общая картина

**Master Node** (Controller manager <- API Server -> Scheduler, etcd)  -> **Worker Node** (Kubelet, Kube-proxy)

#### Master Node
под кодовым названием «CONTROL PLANE» — это место, 
где выполняется большинство важных задач, связанных с управлением и администрированием кластера. 
В целом, можно выделить четыре основных компонента:
+ Сервер API
+ Планировщик
+ Контроллер управления
+ etcd

#### Сервер API
Наверное, самый главный. «Лицо» Kubernetes.
Для любых манипуляций с кластером приходится обращаться к API-серверу с помощью Kubernetes API. 
Используете **kubectl**, **REST** или любую из клиентских библиотек Kubernetes.
Все они завязаны на API Kubernetes'а и взаимодействуют с API-сервером.
Примечательная особенность API-сервера состоит в том, что *__он умеет масштабироваться по горизонтали.__* 
Другими словами, при резком увеличении количества поступающих запросов 
API-сервер может создавать «клоны» или реплики самого себя, чтобы справиться с нагрузкой.

#### Scheduler (планировщик)
Новый Pod остается в статусе **Pending** до тех пор, пока ему не будет выделен узел для работы.
Каждому Pod’у требуются определенные ресурсы: 
память, CPU, железо… в общем, стандартный набор. 
Планировщик должен решить, какой узел соответствует требованиям Pod’а. 
Поэтому планировщик выполняет два действия:
1) Подбирает узлы-кандидаты для Pod’а;
2) Останавливает свой выбор на одном из них.

#### Controller manager
Если что-то идёт не так, контроллер предпринимает соответствующие действия для исправления ситуации.
Иными словами, у кластера есть состояние, называемое желаемым (англ. desired state). 
Именно в таком состоянии должен находиться кластер. Контроллер считает его единственно верным. 
С другой стороны, в каждый момент времени кластер находится в состоянии, называемом текущим (current state). 
Контроллеры будут делать всё, чтобы привести текущее состояние к желаемому.

На самом деле контроллер — это просто бесконечный цикл, который постоянно следит за неким ресурсом в кластере (например, за Pod’ом). 
Если что-то идет не так, он исправляет возникшую проблему.
Теперь вернёмся к нашему менеджеру.
**Менеджер контроллеров (Controller Manager)** — это набор различных контроллеров. 
Например, может быть один контроллер, который наблюдает за узлами, другой — за задачами (Jobs), и так далее.
Но такой менеджер — это инструмент «всё в одном». 
По сути, он отслеживает сразу все ресурсы. 
За это отвечает ОДИН процесс, но благодаря многозадачности складывается впечатление, 
что одновременно работают несколько контроллеров. 
Вот некоторые из самых популярных:
- Node Controller
- Replication Controller
- Service account & Token Controller

#### Etcd
**Etcd** — это личный журнал Kubernetes. 
Всё, что происходит в кластере, должно быть записано и сохранено. 
Вообще всё! И тут на сцену выходит etcd. 
Эта база данных типа ключ-значение выступает резервным хранилищем для Kubernetes.

### «Команда» рабочих узлов (worker node)
Мы уже рассмотрели, что такое master node. 
Но настоящая работа происходит именно на рабочих узлах. 
А всё потому, что на каждом узле есть компоненты, отвечающие за его бесперебойное функционирование. 
**Они включают в себя:**
+ kubelet;
+ kube-proxy;
+ container runtime(среда выполнения контейнера)

#### kubelet
**kubelet** — это агент, который следит за тем, чтобы на узле всё работало должным образом. 
Подобная работа подразумевает ряд задач.

*Первая — взаимодействие с мастер-узлом.* 
Обычно master node отправляет задачу в форме манифеста или спецификации (Podspec). 
Манифест определяет, какие работы необходимо провести и какие Pod’ы нужно создать.
*Вторая — взаимодействие с исполняемой средой контейнера (container runtime) на node*.
Исполняемая среда скачивает нужные образы, после чего вступает в действие kubelet, мониторя Pod’ы,
созданные с использованием этих образов.

*Третья — проверки (probes) состояния Pod’ов.*
Кто отвечает за них? Конечно же, kubelet! 
Потому что следить за здоровьем Pod’а — его обязанность!

#### kube-proxy
Следующий неотъемлемый элемент — работа с сетью, и **kube-proxy** готов позаботиться об этом. 
Он работает как балансировщик нагрузки, распределяя трафик между Pod’ами, а также следит за соблюдением сетевых правил. 
Можно сказать, что kube-proxy полностью отвечает за коммуникации внутри кластера.


## Workloads (Рабочие нагрузки) Kubernetes

### Зачем нужны Workloads (рабочие нагрузки)?
Может случиться так, что Node выйдет из строя или внезапно выйдет из строя. 
Это все равно, что сносить старые здания. 
Теперь, приложив некоторые усилия, вам удается вернуть Node обратно или, возможно, 
подготовить новый Node взамен предыдущего (более новой конструкции).
Но подождите. Что вы собираетесь делать с подами, которые работали на неисправном Node? 
(Node выходит из строя, поды на нем тоже выходят из строя). 
Теперь эти поды должны работать на новом Node. Так же, как и горожане, которые жили в старых кварталах.
Кто будет это делать? Кто будет отслеживать, какие модули приложений должны быть созданы? 
Кто будет отслеживать, сколько подов приложения должно выполняться в данный момент времени?
правильно... *Ресурсы рабочей нагрузки.*

**Рабочая нагрузка** — это способ обработки модулей pod в кластере.
Ну и выбранный набор подов в реальности.
Можно сказать, что рабочая нагрузка — это приложение. 
После указания ресурса Workloads **его задача заключается в создании модулей pod 
и обеспечении постоянной работы фиксированного числа модулей pod.**


### Как работают Workloads (рабочие нагрузки)?
Workloads в Kubernetes — это скорее концепция, чем реальный ресурс. 
По сути, вы берете свое приложение и классифицируете его как определенный тип рабочей нагрузки. 
Все зависит от того, что делает код вашего приложения.
Теперь, когда вы говорите, что ваше приложение принадлежит, скажем, к типу рабочей нагрузки 'X', 
на сцену также выходит *контроллер*, который обрабатывает рабочую нагрузку. 
И контроллер будет поддерживать желаемое состояние для подов вашего приложения, 
и если есть разница в текущем состоянии, 
он всегда будет пытаться предпринять соответствующие шаги для достижения желаемого состояния.
