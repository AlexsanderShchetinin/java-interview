## Индексы БД

Предположим, что у нас есть такая таблица:
```sqlite-sql
CREATE TABLE test1 (
id integer,
content varchar
);
```
и приложение выполняет много подобных запросов:
```sqlite-psql
SELECT content FROM test1 WHERE id = константа;
```
Если система не будет заранее подготовлена, ей придётся сканировать всю таблицу test1,
строку за строкой, чтобы найти все подходящие записи. Когда таблица test1 содержит большое
количество записей, а этот запрос должен вернуть всего несколько (возможно, одну или ноль),
такое сканирование, очевидно, неэффективно. Но если создать в системе индекс по полю id, она
сможет находить строки гораздо быстрее. Возможно, для этого ей понадобится опуститься всего
на несколько уровней в дереве поиска

Создать индекс для столбца id рассмотренной ранее таблицы можно с помощью следующей
команды:
```sqlite-psql
CREATE INDEX test1_id_index ON test1 (id);
```
Имя индекса **test1_id_index** может быть произвольным, главное, чтобы оно позволяло понять,
для чего этот индекс.
Для удаления индекса используется команда **DROP INDEX**. Добавлять и удалять индексы можно в
любое время.
Когда индекс создан, никакие дополнительные действия не требуются: система сама будет
обновлять его при изменении данных в таблице и сама будет использовать его в запросах, где,
по её мнению, это будет эффективнее, чем сканирование всей таблицы. Вам, возможно, придётся
только периодически запускать команду **ANALYZE** для обновления статистических данных, на
основе которых планировщик запросов принимает решения.



## Шардирование БД
это метод  масштабирования, при котором данные разбиваются на несколько частей, называемых «шардами». 
Каждый шард представляет собой отдельную базу данных или таблицу, которая хранит часть данных.
Это позволяет распределять нагрузку между несколькими серверами и улучшать производительность системы.

или

**Шардинг (сегментирование)** — паттерн архитектуры базы данных, 
предполагающий разбиение базы данных на более мелкие, быстрые и управляемые части, называемые шардами (сегментами)

_Выделяют два вида шардирования:_

**_Горизонтальное_**. 
Подразумевает разделение таблицы базы данных на несколько баз данных или экземпляров базы данных. 
Каждый шард сохраняет одну и ту же структуру таблицы, но содержит разное подмножество данных, 
обычно разделяемое на основе ключа шарда.

**_Вертикальное_**. 
Предполагает разделение базы данных на более мелкие подмножества, где каждый шард содержит подмножество таблиц базы данных. 
Этот метод подходит для баз данных, в которых к определённым таблицам обращаются чаще, чем к другим, 
что позволяет снизить нагрузку на таблицы, в которые направляется большое количество запросов.

#### Существует несколько основных методов шардирования данных:

* **Хешированное.** 
Данные разбиваются на шарды на основе хеш-функции, которая принимает входные данные и возвращает хеш-значение. 
Это значение определяет, в какой шард будет помещена каждая запись данных.
* **Диапазонное.** 
Данные разбиваются на шарды на основе диапазона значений. 
Метод прост в реализации и позволяет быстрее находить информацию, чем при хешировании,
однако может привести к несбалансированности базы.
* **Круговое.**
Шарды упорядочиваются в виде кольца и каждый из них ответственен за определённый диапазон значений. 
Запросы на данные маршрутизируются в соответствии с позицией шарда в кольце.
* **Динамическое.** 
Позволяет автоматически масштабировать хранилище в зависимости от текущей производительности и объёма данных. 

### Простой пример «как сделать руками»

Условный шардинг можно выпилить посредством тестовой таблицы test.documents на 32 документа, 
и генерацией из этой таблицы 16 тестовых таблиц примерно по 2 документа test.docs00, 01, 02, ..., 15.

```sqlite-psql
INSERT INTO docs00
SELECT * FROM documents 
WHERE (id%16)=0
...

INSERT INTO docs15
SELECT * FROM documents 
WHERE (id%16)=15
```
_WHERE (id%16)=0:_ Это условие фильтрации, которое говорит о том, что выбираются только те записи, 
у которых значение столбца id, при делении на 16, даёт в остатке 0. 
_То есть выбираются только те записи, где id является кратным 16._

Делаем мы это вот зачем. После того, как мы сделали 16 таблиц, мы можем «захавать» 16 того, что нам нужно. 
Вне зависимости от того, во что мы уперлись, мы можем на эти ресурсы распараллелиться. 
Например, если не хватает дискового пространства, будет иметь смысл разложить эти таблицы по отдельным дискам.

Все это, к несчастью, не бесплатно. Подозреваю, что в случае с каноническим SQL-стандартом, 
нет официального стандартизированного синтаксиса для того, чтобы любому SQL-серверу сказать: 
«Дорогой SQL-сервер, сделай мне 32 шарда и разложи их на 4 диска». 
Но в отдельно взятых реализациях зачастую есть конкретный синтаксис для того, чтобы сделать в принципе то же самое. 
В PostgreSQL есть механизмы для партиционирования, в MySQL MariaDB есть, Oracle наверняка это все сделал уже давным-давно.

Тем не менее, если мы это делаем руками, без поддержки базы данных и в рамках стандарта, 
то платим условно сложностью доступа к данным. 
Там, где было простое SELECT * FROM documents WHERE id=123, теперь 16 x SELECT * FROM docsXX. 
И хорошо, если мы пытались доставать запись по ключу. 
Значительно более интересно, если мы пытались доставать ранний диапазон записей. 
Теперь (если мы, подчеркиваю, как бы дураки, и остаемся в рамках стандарта) 
результаты этих 16 SELECT * FROM придется объединять в приложении.

Какого изменения производительности ожидать?

Интуитивно — линейного.
Теоретически — сублинейного, потому что Amdahl law.
Практически — может быть, почти линейно, может быть, нет.

На самом деле, правильный ответ — неизвестно. 
Ловким применением техники шардирования можно добиться значительного сверхлинейного **ухудшения** работы вашего приложения, 
да еще DBA прибежит с раскаленной кочергой.

Посмотрим, как этого можно добиться. 
Понятно, что просто поставить настройку в PostgreSQL shards=16, а дальше оно само взлетело — это не интересно. 
Давайте подумаем, как можно добиться того, чтобы от шардирования в 16 раз мы бы затормозили в 32 — 
это интересно с той точки зрения, как бы этого не делать.

Наши попытки ускориться либо затормозить всегда будут упираться в классику — в старый добрый закон Амдала (Amdahl law), 
который говорит, что не бывает идеальной распараллелизации любого запроса, всегда есть некая последовательная часть.

 ### Amdahl law

**_Всегда есть serialized часть._**

Всегда есть часть исполнения запроса, которая параллелится, и всегда есть часть, которая не параллелится. 
Даже если вам кажется, что идеально параллелещийся запрос, как минимум сбор строки результата, которую вы собираетесь отослать на клиента,
из строк, полученных с каждого шарда, всегда есть, и он всегда последовательный.

Всегда есть какая-то последовательная часть. 
Она может быть крохотной, абсолютно незаметной на общем фоне, она может быть гигантской и, соответственно, 
сильно влияющей на параллелизацию, но она есть всегда.

Кроме того, её влияние меняется и может ощутимо подрасти, например, если мы нарежем нашу таблицу — 
давайте поднимем ставки — из 64 записей на 16 таблиц по 4 записи, эта часть изменится. 
Конечно же, судя по таким гигантским объемам данных, мы работаем на мобильном телефоне и 86 процессоре 2 МГц, 
у нас и файлов-то не хватает, которые можно одновременно держать открытыми. 
Видимо, с такими вводными, мы по одному файлу за раз открываем.

Было ```Total = Serial + Parallel.``` Где, например, parallel — это вся работа внутри DB, а serial — отправка результата в клиента.
Стало ```Total2 = Serial + Parallel/N + Xserial.``` Например, когда общий ORDER BY, Xserial>0.

Этим нехитрым примером я пытаюсь показать, что появляется некое **Xserial**. 
Кроме того, что всегда есть сериализованная часть, и того, что мы пытаемся работать с данными параллельно, 
появляется дополнительная часть для обеспечения этой нарезки данных. Грубо говоря, нам может понадобиться:

- найти во внутреннем словаре базы данных эти 16 таблиц;
- открыть файлы;
- аллоцировать память;
- разаллоцировать память;
- смерджить результаты;
- синхронизироваться между ядрами;

Какие-то рассинхронизационные эффекты все равно обязательно появляются. 
Они могут быть ничтожными и занимать одну миллиардную от общего времени, но всегда ненулевые и всегда есть. 
С их-то помощью мы и можем резко потерять в производительности после шардирования.

Предположим, что у нас есть некая сериализованная часть обработки запроса, которая занимает всего 5%: serial = 0.05 = 1 / 20.

Интуитивно казалось бы, что при сериализованной части, которая занимает всего 1/20 от обработки запроса, 
если мы распараллелим обработку запроса на 20 ядер, она станет примерно в 20, в худшем случае в 18, раз быстрее.

На самом деле математика — штука бессердечная:

```
wall = 0.05 + 0.95/num_cores, 
speedup = 1 / (0.05 + 0.95/num_cores)
```

Оказывается, что если аккуратно посчитать, при сериализованной части в 5%, ускорение будет в 10 раз (10,3), 
а это 51% по сравнению с теоретическим идеальным.